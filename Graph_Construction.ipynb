{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os, sys, csv, time\n",
    "from Bio import SeqIO\n",
    "from Bio.SeqRecord import SeqRecord\n",
    "import numpy as np\n",
    "import networkx as nx\n",
    "from itertools import izip\n",
    "from Bio.Alphabet import IUPAC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['genbank',\n",
       " 'fastas',\n",
       " 'backup',\n",
       " '.ipynb_checkpoints',\n",
       " 'concat',\n",
       " 'Header-Reprocessing.ipynb',\n",
       " 'Graph_Construction.ipynb',\n",
       " 'alignments_test']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.listdir('.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "r6_modified = list(SeqIO.parse('fastas/R6_new.mfa', 'fasta'))\n",
    "r6_original = list(SeqIO.parse('backup/R6.mfa', 'fasta'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R6.1_1\n",
      "lcl|AE007317.1_prot_AAK98805.1_1\n"
     ]
    }
   ],
   "source": [
    "print r6_modified[0].id\n",
    "print r6_original[0].id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def dict_maker(modified_files, original_files):\n",
    "    mod_list = []\n",
    "    orig_list = []\n",
    "    for index in xrange(len(modified_files)):\n",
    "        mod_rec = list(SeqIO.parse(modified_files[index], 'fasta'))\n",
    "        orig_rec = list(SeqIO.parse(original_files[index], 'fasta'))\n",
    "        for index2 in xrange(len(mod_rec)):\n",
    "                mod_list.append(mod_rec[index2].id)\n",
    "                orig_list.append(orig_rec[index2].id)\n",
    "    return dict(izip(mod_list, orig_list)), mod_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Paths to fasta and backup files.\n",
    "fastapath = '/home/jacob/Documents/CMU/Research/Genomes/fastas/'\n",
    "backup = '/home/jacob/Documents/CMU/Research/Genomes/backup/'\n",
    "\n",
    "\n",
    "modified_files = [fastapath + 'ATCC700669_new.mfa', fastapath + 'D39_new.mfa', fastapath + 'G54_new.mfa', \\\n",
    "                  fastapath + 'TIGR4_new.mfa', fastapath + 'R6_new.mfa']\n",
    "\n",
    "original_files = [backup + 'ATCC700669.mfa', backup + 'D39.mfa', backup + 'G54.mfa', \\\n",
    "                 backup + 'TIGR4.mfa', backup + 'R6.mfa']\n",
    "\n",
    "nucl_fastas = os.listdir(fastapath + 'nucl/')\n",
    "\n",
    "headers_dict, mod_list = dict_maker(modified_files, original_files) \n",
    "\n",
    "def reverse(dict):\n",
    "    return {v: k for k, v in dict.iteritems()}\n",
    "\n",
    "inv_head_dict = reverse(headers_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "with open('concat/mcl_clusters', 'r') as infile:\n",
    "    reader = csv.reader(infile, delimiter='\\t')\n",
    "    clusters = list(reader)\n",
    "\n",
    "def cluster_dict_maker(cluster_file, mod_list):\n",
    "    mod_comp = [[i] for i in mod_list]\n",
    "    for index, cluster in enumerate(cluster_file):\n",
    "        for element in cluster:\n",
    "            mod_comp[mod_list.index(element)].append(index)\n",
    "    return dict(mod_comp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cluster_dict = cluster_dict_maker(clusters, mod_list)\n",
    "gb_dict = {\"AP200\":\"CP002121\",\\\n",
    "                \"670-6B\":\"CP002176\",\\\n",
    "                \"70585\":\"CP000918\",\\\n",
    "                \"ATCC700669\":\"FM211187.1\",\\\n",
    "                \"CGSP14\":\"CP001033\",\\\n",
    "                \"D39\":\"CP000410.1\",\\\n",
    "                \"G54\":\"CP001015.1\",\\\n",
    "                \"Hu19A\":\"CP000936\",\\\n",
    "                \"INV104\":\"FQ312030\",\\\n",
    "                \"INV200\":\"FQ312029\",\\\n",
    "                \"JJA\":\"CP000919\",\\\n",
    "                \"OXC141\":\"FQ312027\",\\\n",
    "                \"P1031\":\"CP000920\",\\\n",
    "                    \"SPN032672\":\"NC_021003\",\\\n",
    "                \"SPN033038\":\"NC_021004\",\\\n",
    "                \"SPN034183\":\"FQ312043\",\\\n",
    "                \"SPN994038\":\"FQ312041\",\\\n",
    "                \"SPN994039\":\"FQ312044\",\\\n",
    "                \"SPN034156\":\"FQ312045\",\\\n",
    "                \"T19F\":\"CP000921.1\",\\\n",
    "                \"TIGR4\":\"AE005672.3\",\\\n",
    "                \"R6\":\"NC_003098.1\"}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TIGR4.gb\n",
      "AE005672.3\n",
      "D39.gb\n",
      "CP000410.1\n",
      "G54.gb\n",
      "CP001015.1\n",
      "ATCC700669.gb\n",
      "FM211187.1\n",
      "R6.gb\n",
      "NC_003098.1\n"
     ]
    }
   ],
   "source": [
    "gbks = '/home/jacob/Documents/CMU/Research/Genomes/genbank/'\n",
    "ATCC = list(SeqIO.parse(gbks+'ATCC700669.gb', 'genbank'))\n",
    "\n",
    "for filename in os.listdir(gbks):\n",
    "    if filename.split('.')[-1] == 'gb':\n",
    "        blahblah = list(SeqIO.parse(gbks+filename, 'genbank'))\n",
    "        print filename\n",
    "        print(blahblah[0].id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## So shit with the headers is mighty confusing. Sometimes there's a '.1' or '.3' at the end, sometimes it's a bunch of irrelevant alphanumeric logorrhea, sometimes it's my simplified headers. So now I have to make a way to standardize the protein IDs.\n",
    "\n",
    "## Retroactive note: I just used the dictionary I made for another script. Someday I will have my revenge, NCBI."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2135"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feats = [feat for feat in ATCC[0].features if feat.type == \"CDS\"]\n",
    "len(feats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def strand_switch(start, end):\n",
    "    #Compensate for strand ridiculousness\n",
    "    if end < start:\n",
    "        return end, start\n",
    "    else:\n",
    "        return start, end\n",
    "\n",
    "\n",
    "def graph_constructor(genbank, cluster_dict, gb_dict):\n",
    "    genome_id = gb_dict[genbank[0].id] #Get the non-bullshit version of the ID, thanks genbank\n",
    "    feats = [feat for feat in genbank[0].features if feat.type == \"CDS\"]\n",
    "    cluster_assignments = []\n",
    "    G = nx.Graph()\n",
    "    edge_locations = []\n",
    "    \n",
    "    for index, feat in enumerate(feats): #Make list of cluster memberships, distances to proximal genes\n",
    "        if index == len(feats)-1:\n",
    "            break\n",
    "        cluster_assignments.append([])\n",
    "        \n",
    "        if genome_id + '.1_' + str(index+1) in cluster_dict:\n",
    "            cluster_id = cluster_dict[genome_id + '.1_' + str(index+1)]\n",
    "        elif genome_id + '.1_prot_' + str(index+1) in cluster_dict:\n",
    "            cluster_id = cluster_dict[genome_id + '.1_prot_' + str(index+1)]\n",
    "        else:\n",
    "            cluster_id = cluster_dict[genome_id + '.2_' + str(index+1)]\n",
    "        cluster_assignments[-1].append(cluster_id) #Make sure this accesses right\n",
    "        \n",
    "        cur_start = feat.location.start\n",
    "        cur_end = feat.location.end\n",
    "        cur_strand = feat.location.strand\n",
    "        cur_feat = feat\n",
    "        start, end = strand_switch(cur_start, cur_end)\n",
    "        \n",
    "        next_start = feats[index+1].location.start\n",
    "        next_end = feats[index+1].location.end\n",
    "        next_strand = feats[index+1].location.strand\n",
    "        next_feat = feats[index+1]\n",
    "        next_start, next_end = strand_switch(next_start, next_end) \n",
    "        if genome_id + '.1_' + str(index+2) in cluster_dict:\n",
    "            next_cluster_id = cluster_dict[genome_id + '.1_' + str(index+2)]\n",
    "        elif genome_id + '.1_prot_' + str(index+2) in cluster_dict:\n",
    "            next_cluster_id = cluster_dict[genome_id + '.1_prot_' + str(index+2)]\n",
    "        else: \n",
    "            cluster_id = cluster_dict[genome_id + '.2_' + str(index+2)]\n",
    "        if next_cluster_id not in G.nodes():\n",
    "            #If the next gene belongs to an unseen cluster, add a node for it\n",
    "            G.add_node(next_cluster_id)\n",
    "        \n",
    "        G.add_edge(cluster_id, next_cluster_id, weight=next_start-end)\n",
    "        edge_locations.append([genome_id, cur_end, next_start, abs(cur_end - next_start), cur_feat, next_feat])\n",
    "        \n",
    "    return G, cluster_assignments, edge_locations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Testing!\n",
    "ATCC_Graph, ATCC_clusts, ATCC_edgelocations = graph_constructor(ATCC, cluster_dict, reverse(gb_dict))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Awesome. So the graph generator works (whether or not it works infallibly is yet to be determined); now I have to generate all the graphs, then find a way to remove edges that don't exist in each graph."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "ordered_file_list = []\n",
    "graph_list = []\n",
    "cluster_lists = []\n",
    "bed_lists = [] #Will contain all genome ID/insert position info\n",
    "\n",
    "def edge_subgraph(mg_edgelist, graph_list):\n",
    "    for graph in graph_list:\n",
    "        cur_edgelist = list(graph.edges_iter())\n",
    "        for edge in mg_edgelist:\n",
    "            if edge not in cur_edgelist:\n",
    "                del mg_edgelist[mg_edgelist.index(edge)]\n",
    "    return mg_edgelist\n",
    "\n",
    "def induce_subgraph_from_edgelist(G, edge_list, ref_back=True):\n",
    "    #Ripped from https://stackoverflow.com/questions/16150557/networkxcreating-a-subgraph-induced-from-edges\n",
    "    sub_nodes = list({y for x in edge_list for y in x[0:2]})\n",
    "    edge_list_no_data = [edge[0:2] for edge in edge_list]\n",
    "    assert all([e in G.edges() for e in edge_list_no_data])\n",
    "\n",
    "    if ref_back:\n",
    "        G_sub = G.subgraph(sub_nodes)\n",
    "        for edge in G_sub.edges():\n",
    "            if edge not in edge_list_no_data:\n",
    "                G_sub.remove_edge(*edge)\n",
    "    else:\n",
    "        G_sub = G.subgraph(sub_nodes).copy()\n",
    "        for edge in G_sub.edges():\n",
    "            if edge not in edge_list_no_data:\n",
    "                G_sub.remove_edge(*edge)\n",
    "\n",
    "    return G_sub\n",
    "\n",
    "for filename in os.listdir(gbks):\n",
    "    if filename.split('.')[-1] == 'gb':\n",
    "        ordered_file_list.append(filename.split('.')[0])\n",
    "        genbank = list(SeqIO.parse(gbks+filename, 'genbank'))\n",
    "        cur_graph, cur_clusts, cur_edges = graph_constructor(genbank, cluster_dict, reverse(gb_dict))\n",
    "        graph_list.append(cur_graph)\n",
    "        cluster_lists.append(cur_clusts)\n",
    "        bed_lists.append(cur_edges)\n",
    "\n",
    "    \n",
    "#Make a metagraph cotaining each edge from all graphs\n",
    "metagraph = nx.Graph()\n",
    "for graph in graph_list:\n",
    "    metagraph.add_edges_from(graph.edges(data=False))\n",
    "\n",
    "#Make a masked array to track which edges are preserved; DON'T USE GRAPH_LIST[0]\n",
    "masked_arr = np.zeros(len(metagraph.edges()))\n",
    "\n",
    "meta_edgelist = list(metagraph.edges_iter())\n",
    "\n",
    "#Named sub_graph instead of subgraph because there's a networkx method called .subgraph()\n",
    "sub_graph = metagraph\n",
    "\n",
    "for genome in graph_list:\n",
    "    subgraph_edgelist = edge_subgraph(meta_edgelist, graph_list)\n",
    "    #Remove self-edges; almost entirely adjacent transposons, which we will look at later\n",
    "    subgraph_edgelist = [edge for edge in subgraph_edgelist if edge[0] != edge[1]]\n",
    "    sub_graph = induce_subgraph_from_edgelist(sub_graph, subgraph_edgelist)\n",
    "\n",
    "\"\"\"\n",
    "#Remove self-edges in sub_graph (Transposons messing up my life; look at them later)\n",
    "for (u,v,d) in sub_graph.edges_iter(data='weight'):\n",
    "    if u == v:\n",
    "        sub_graph.remove_edge(u,v)\n",
    "\"\"\"\n",
    "\n",
    "#Create filtered information based on edges\n",
    "sg_edgelist = list(sub_graph.edges_iter()) \n",
    "edgelist_list = []\n",
    "\n",
    "#Make list of edge lists for each genome graph\n",
    "for graph in graph_list:\n",
    "    edgelist_list.append(list(graph.edges_iter()))\n",
    "                         \n",
    "                         \n",
    "bed_list = []\n",
    "\n",
    "for index, edge in enumerate(meta_edgelist):\n",
    "    if edge in sg_edgelist:\n",
    "        masked_arr[index] = 1 #Index in masked array\n",
    "        bed_list.append([])\n",
    "        for genome_num in xrange(len(graph_list)):\n",
    "            genome_id = ordered_file_list[genome_num].split('.')[0]\n",
    "            edgeno = edgelist_list[genome_num].index(edge)\n",
    "            #Append in format [Genome ID, edge coordinate 1, edge coordinate 2]\n",
    "            #to add: upstream/downstream features? maybe protein IDs? We're gonna make this into a dataframe anyway\n",
    "            bed_list[-1].append(bed_lists[genome_num][edgeno])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Subgraph edges:\n",
      "871\n",
      "graph_list[0] edges:\n",
      "2111\n",
      "graph_list[1] edges:\n",
      "1909\n",
      "graph_list[2] edges:\n",
      "2089\n",
      "graph_list[3] edges:\n",
      "2127\n",
      "graph_list[4] edges:\n",
      "1784\n"
     ]
    }
   ],
   "source": [
    "print(\"Subgraph edges:\")\n",
    "print(len(sub_graph.edges()))\n",
    "for idx in xrange(len(graph_list)):\n",
    "    print(\"graph_list[\" + str(idx) + \"] edges:\")\n",
    "    print(len(graph_list[idx].edges()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## HELLA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['TIGR4', ExactPosition(2853), ExactPosition(2863), 10, SeqFeature(FeatureLocation(ExactPosition(1716), ExactPosition(2853), strand=1), type='CDS'), SeqFeature(FeatureLocation(ExactPosition(2863), ExactPosition(3112), strand=1), type='CDS')], ['D39', ExactPosition(2657), ExactPosition(2721), 64, SeqFeature(FeatureLocation(ExactPosition(1520), ExactPosition(2657), strand=1), type='CDS'), SeqFeature(FeatureLocation(ExactPosition(2721), ExactPosition(2916), strand=1), type='CDS')], ['G54', ExactPosition(3112), ExactPosition(3195), 83, SeqFeature(FeatureLocation(ExactPosition(2917), ExactPosition(3112), strand=1), type='CDS'), SeqFeature(FeatureLocation(ExactPosition(3195), ExactPosition(4311), strand=1), type='CDS')], ['ATCC700669', ExactPosition(2842), ExactPosition(2906), 64, SeqFeature(FeatureLocation(ExactPosition(1705), ExactPosition(2842), strand=1), type='CDS'), SeqFeature(FeatureLocation(ExactPosition(2906), ExactPosition(3101), strand=1), type='CDS')], ['R6', ExactPosition(2657), ExactPosition(2721), 64, SeqFeature(FeatureLocation(ExactPosition(1520), ExactPosition(2657), strand=1), type='CDS'), SeqFeature(FeatureLocation(ExactPosition(2721), ExactPosition(2916), strand=1), type='CDS')]]\n"
     ]
    }
   ],
   "source": [
    "print bed_list[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def check_for_insert(sublist):\n",
    "    insert_sizes = []\n",
    "    for genome_fragment in sublist:\n",
    "        insert_sizes.append(genome_fragment[2] - genome_fragment[1])\n",
    "    for i in xrange(len(insert_sizes)):\n",
    "        for j in xrange(len(insert_sizes) - i):\n",
    "            if abs(insert_sizes[i] - insert_sizes[j]) >= 150:\n",
    "                return True\n",
    "    return False\n",
    "\n",
    "filtered_list = []\n",
    "for sublist in bed_list:\n",
    "    if check_for_insert(sublist):\n",
    "        filtered_list.append(sublist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['TIGR4', ExactPosition(678099), ExactPosition(678710), 611, SeqFeature(FeatureLocation(ExactPosition(676623), ExactPosition(678099), strand=1), type='CDS'), SeqFeature(FeatureLocation(ExactPosition(678710), ExactPosition(680057), strand=-1), type='CDS')], ['D39', ExactPosition(579349), ExactPosition(579653), 304, SeqFeature(FeatureLocation(ExactPosition(577873), ExactPosition(579349), strand=1), type='CDS'), SeqFeature(FeatureLocation(ExactPosition(579653), ExactPosition(586340), strand=1), type='CDS')], ['G54', ExactPosition(625830), ExactPosition(626062), 232, SeqFeature(FeatureLocation(ExactPosition(625197), ExactPosition(625830), strand=1), type='CDS'), SeqFeature(FeatureLocation(ExactPosition(626062), ExactPosition(626413), strand=1), type='CDS')], ['ATCC700669', ExactPosition(695540), ExactPosition(695523), 17, SeqFeature(FeatureLocation(ExactPosition(694340), ExactPosition(695540), strand=1), type='CDS'), SeqFeature(FeatureLocation(ExactPosition(695523), ExactPosition(696225), strand=1), type='CDS')], ['R6', ExactPosition(586930), ExactPosition(586940), 10, SeqFeature(FeatureLocation(ExactPosition(586336), ExactPosition(586930), strand=1), type='CDS'), SeqFeature(FeatureLocation(ExactPosition(586940), ExactPosition(588053), strand=1), type='CDS')]]\n"
     ]
    }
   ],
   "source": [
    "print filtered_list[205]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-62-787749756b0a>, line 6)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-62-787749756b0a>\"\u001b[0;36m, line \u001b[0;32m6\u001b[0m\n\u001b[0;31m    fasta_dict = {'ATCC700669':ATCC, 'G54':G54, 'D39':D    sys.exit()\u001b[0m\n\u001b[0m                                                             ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "ATCC = list(SeqIO.parse(fastapath + 'nucl/ATCC700669.fasta', 'fasta'))\n",
    "G54 = list(SeqIO.parse(fastapath + 'nucl/G54.fasta', 'fasta'))\n",
    "D39 = list(SeqIO.parse(fastapath + 'nucl/D39.fasta', 'fasta'))\n",
    "TIGR4 = list(SeqIO.parse(fastapath + 'nucl/TIGR4.fasta', 'fasta'))\n",
    "R6 = list(SeqIO.parse(fastapath + 'nucl/R6.fasta', 'fasta'))\n",
    "fasta_dict = {'ATCC700669':ATCC, 'G54':G54, 'D39':D    sys.exit()\n",
    "39, 'TIGR4':TIGR4, 'R6':R6}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 ['TIGR4', ExactPosition(25416), ExactPosition(25417), 1, SeqFeature(FeatureLocation(ExactPosition(24972), ExactPosition(25416), strand=1), type='CDS'), SeqFeature(FeatureLocation(ExactPosition(25417), ExactPosition(25933), strand=1), type='CDS')]\n",
      "1 ['D39', ExactPosition(4115), ExactPosition(4185), 70, SeqFeature(FeatureLocation(ExactPosition(2999), ExactPosition(4115), strand=1), type='CDS'), SeqFeature(FeatureLocation(ExactPosition(4185), ExactPosition(4755), strand=1), type='CDS')]\n",
      "2 ['G54', ExactPosition(23826), ExactPosition(24076), 250, SeqFeature(FeatureLocation(ExactPosition(23709), ExactPosition(23826), strand=1), type='CDS'), SeqFeature(FeatureLocation(ExactPosition(24076), ExactPosition(24520), strand=1), type='CDS')]\n",
      "3 ['ATCC700669', ExactPosition(27549), ExactPosition(27603), 54, SeqFeature(CompoundLocation([FeatureLocation(ExactPosition(27219), ExactPosition(27549), strand=-1), FeatureLocation(ExactPosition(26407), ExactPosition(27220), strand=-1)], 'join'), type='CDS', location_operator='join'), SeqFeature(FeatureLocation(ExactPosition(27603), ExactPosition(28674), strand=-1), type='CDS')]\n",
      "4 ['R6', ExactPosition(10338), ExactPosition(10334), 4, SeqFeature(FeatureLocation(ExactPosition(9000), ExactPosition(10338), strand=1), type='CDS'), SeqFeature(FeatureLocation(ExactPosition(10334), ExactPosition(11612), strand=1), type='CDS')]\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-72-7d714d59fa5b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     37\u001b[0m     \u001b[0mseq_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpull_seqs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_list\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m     \u001b[0mdownstream_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mupstream_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpull_seqs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_list\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprotein\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 39\u001b[0;31m     \u001b[0;32mprint\u001b[0m \u001b[0mdownstream_list\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     40\u001b[0m     \u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"seqgroup_\"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m\".fasta\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'w'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0moutput_handle\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "def sense(start, end):\n",
    "    if start > end:\n",
    "        start, end = end, start\n",
    "    return start, end\n",
    "\n",
    "def pull_seqs(sublist, protein=False):\n",
    "    if protein:\n",
    "        upstream_list = []\n",
    "        downstream_list = []\n",
    "        for index, element in enumerate(sublist):\n",
    "            try:\n",
    "                upstream_list.append(SeqRecord(seq=element[-1].qualifiers[('translation')][0], \\\n",
    "                                               id=element[0] + '_' + str(index), description=\"\", \\\n",
    "                                               alphabet=IUPAC.protein))\n",
    "            except TypeError:\n",
    "                print index, element\n",
    "            except:\n",
    "                pass\n",
    "            try:\n",
    "                downstream_list.append(SeqRecord(seq=element[-1].qualifiers[('translation')][0], \\\n",
    "                                               id=element[0] + '_' + str(index), description=\"\", \\\n",
    "                                                 alphabet=IUPAC.protein))\n",
    "            except:\n",
    "                pass\n",
    "        return downstream_list, upstream_list\n",
    "    else:\n",
    "        seq_list = []\n",
    "        for index, element in enumerate(sublist):\n",
    "            start, end = sense(element[1], element[2])\n",
    "            seq_list.append(SeqRecord(fasta_dict[element[0]][0].seq[start:end], \\\n",
    "                                      id=element[0] + '_' + str(index), description=\"\"))\n",
    "        return seq_list\n",
    "\n",
    "def fix_null(list):\n",
    "    new_list = []\n",
    "    for element in list:\n",
    "        if element != []:\n",
    "            new_list.append(element)\n",
    "    return new_list\n",
    "\n",
    "for i in xrange(len(filtered_list)):\n",
    "    seq_list = pull_seqs(filtered_list[i])\n",
    "    downstream_list, upstream_list = pull_seqs(filtered_list[i], protein=True)\n",
    "    print downstream_list[0]\n",
    "    sys.exit()\n",
    "    with open(\"seqgroup_\" + str(i) + \".fasta\", 'w') as output_handle:\n",
    "        SeqIO.write(seq_list, output_handle, \"fasta\")\n",
    "    with open(\"seqgroup_\" + str(i) + \"_downstream.faa\", 'w') as output_handle:\n",
    "        SeqIO.write(downstream_list, output_handle, \"fasta\")\n",
    "    with open(\"seqgroup_\" + str(i) + \"_upstream.faa\", 'w') as output_handle:\n",
    "        SeqIO.write(upstream_list, output_handle, \"fasta\")\n",
    "    os.system('mkdir run' + str(i) + ' && mv seqgroup_' + str(i) + '* run' + str(i))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['MKIRGFELVSSFTDENLLPKRETAHAAGYDLKVAVRTVVAPGEIVLVPTGVKAYMQPTEVLYLYDRSSNPRKKGLVLINSVGVIDGDYYGNPGNEGHIFAQMKNITDQEVVLEVGERIVQAVFATFLIADGDAADGVRTGGFGSTGH'], ['MALTAGIVGLPNVGKSTLFNAITKAGAEAANYPFATIDPNVGMVEVPDERLQKLTEMITPKKTVPTTFEFTDIAGIVKGASKGEGLGNKFLANIREVDAIVHVVRAFDDENVMREQGREDAFVDPLADIDTINLELILADLESVNKRYARVEKMARTQKDKESVAEFNVLQKIKPVLEDGKSARTIEFTDEEQKVVKGLFLLTTKPVLYVANVDEDVVSEPDSIDYVKQIREFAATENAEVVVISARAEEEISELDDEDKKEFLEAIGLTESGVDKLTRAAYHLLGLGTYFTAGEKEVRAWTFKRGMKAPQAAGIIHSDFEKGFIRAVTMSYEDLVKYGSEKAVKEAGRLREEGKEYIVQDGDIMEFRFNV'], ['MPAFPNVVYGAKNQKFGAAGSLYNILTDERLNHLWRLK'], ['MKSWKNWLIKINYCVYKKKRKGRMRKFLIILLLPSFLTISKVVSTEKEVVYTSKEIYYLSQSDFGIYFREKLSSPMVYGEVPVYANEDLVVESGKLTPKTSFQITEWRLNKQGIPVFKLSNHQFIAADKRFLYDQSEVTPTIKKVWLESDFKLYNSPYDLKEVKSSLSAYSQVSIDKTMFVEGREFLHIDQAGWVAKESTSEEDNRMSKVQEMLSEKYQKDSFSIYVKQLTTGKEAGINQDEKMYAASVLKLSYLYYTQEKINEGLYQLDTTVKYVSAVNDFPGSYKPEGSGSLPKKEDNKEYSLKDLITKVSKESDNVAHNLLGYYISNQSDATFKSKMSAIMGDDWDPKEKLISSKMAGKFMEAIYNQNGFVLESLTKTDFDSQRIAKGVSVKVAHKIGDADEFKHDTGVVYADSPFILSIFTKNSDYDTISKIAKDVYEVLK']]\n"
     ]
    }
   ],
   "source": [
    "#print filtered_list[0][0][-1].qualifiers[('translation')]\n",
    "downstream_list, upstream_list = pull_seqs(filtered_list[0], protein=True)\n",
    "print downstream_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
